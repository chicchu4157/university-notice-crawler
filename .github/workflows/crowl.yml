name: University Notice Crawler

on:
  # n8n에서 repository_dispatch 이벤트로 트리거
  repository_dispatch:
    types: [crawl-notices]
  
  # 수동 실행도 가능
  workflow_dispatch:
    inputs:
      batch_size:
        description: '한 번에 처리할 대학 수'
        required: false
        default: '50'
      start_index:
        description: '시작 인덱스'
        required: false
        default: '0'

  # 매일 오전 9시 자동 실행 (선택사항)
  schedule:
    - cron: '0 0 * * *'  # UTC 기준 매일 00:00 (한국시간 09:00)

jobs:
  crawl:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Setup Chrome and ChromeDriver
      uses: browser-actions/setup-chrome@latest
    
    - name: Run crawler
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        N8N_WEBHOOK_SECRET: ${{ secrets.N8N_WEBHOOK_SECRET }}
        BATCH_SIZE: ${{ github.event.inputs.batch_size || '50' }}
        START_INDEX: ${{ github.event.inputs.start_index || '0' }}
      run: |
        python main.py
    
    - name: Upload logs
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: crawl-logs
        path: logs/
        retention-days: 30
    
    - name: Notify completion
      if: always()
      run: |
        echo "Crawling completed with status: ${{ job.status }}"
        # 여기에 Slack/Discord 알림 추가 가능
