# ğŸ“ ëŒ€í•™ ê³µì§€ì‚¬í•­ í¬ë¡¤ëŸ¬

200ì—¬ê°œ ëŒ€í•™ì˜ ê³µì§€ì‚¬í•­ì„ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ëŠ” ì§€ëŠ¥í˜• í¬ë¡¤ë§ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì—¬ ìë™ íŒ¨í„´ ê°ì§€, í…œí”Œë¦¿ ê¸°ë°˜, ìˆ˜ë™ ì„¤ì •ì„ ì¡°í•©í•´ ë†’ì€ ì„±ê³µë¥ ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

## âœ¨ ì£¼ìš” íŠ¹ì§•

- **ğŸ§  ì§€ëŠ¥í˜• íŒ¨í„´ ê°ì§€**: AI ê¸°ë°˜ ìë™ êµ¬ì¡° ë¶„ì„
- **ğŸ“‹ í…œí”Œë¦¿ ì‹œìŠ¤í…œ**: ê³µí†µ CMS ìë™ ì¸ì‹
- **ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼**: ë‹¤ë‹¨ê³„ í´ë°± ì‹œìŠ¤í…œ
- **â˜ï¸ GitHub Actions**: ìë™ ìŠ¤ì¼€ì¤„ë§ ë° ì‹¤í–‰
- **ğŸ’¾ Supabase ì—°ë™**: ì‹¤ì‹œê°„ ë°ì´í„° ì €ì¥
- **ğŸ“Š ëª¨ë‹ˆí„°ë§**: ìƒì„¸í•œ ì‹¤í–‰ ë¡œê·¸ ë° í†µê³„

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
n8n íŠ¸ë¦¬ê±° â†’ GitHub Actions â†’ í¬ë¡¤ëŸ¬ ì‹¤í–‰ â†’ Supabase ì €ì¥
```

### í¬ë¡¤ë§ ì „ëµ

1. **ìë™ íŒ¨í„´ ê°ì§€** (80% ì»¤ë²„ë¦¬ì§€ ëª©í‘œ)
   - ë‚ ì§œ íŒ¨í„´ ê¸°ë°˜ êµ¬ì¡° ë¶„ì„
   - ì½˜í…ì¸  ìœ ì‚¬ì„± ê²€ì‚¬
   - ë™ì  ì„ íƒì ìƒì„±

2. **í…œí”Œë¦¿ ë§¤ì¹­** (15% ì»¤ë²„ë¦¬ì§€)
   - ì•„ì¹´í”¼ì•„, ì§„í•™ì–´í”Œë¼ì´ ë“± ê³µí†µ ì‹œìŠ¤í…œ ì¸ì‹
   - ë„ë©”ì¸ë³„ ë§ì¶¤ ì„¤ì •
   - ì‹œìŠ¤í…œ ì§€í‘œ ê¸°ë°˜ ìë™ ë§¤ì¹­

3. **ìˆ˜ë™ ì„¤ì •** (5% ì˜ˆì™¸ ì²˜ë¦¬)
   - íŠ¹ìˆ˜í•œ êµ¬ì¡°ì˜ ì‚¬ì´íŠ¸ ì²˜ë¦¬
   - Selenium í´ë°± ì§€ì›

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì €ì¥ì†Œ ë³µì œ

```bash
git clone <repository-url>
cd university-notice-crawler
```

### 2. GitHub Secrets ì„¤ì •

GitHub ì €ì¥ì†Œì˜ **Settings > Secrets and variables > Actions**ì—ì„œ ë‹¤ìŒ ì‹œí¬ë¦¿ì„ ì„¤ì •í•˜ì„¸ìš”:

```
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-service-role-key
N8N_WEBHOOK_SECRET=your-webhook-secret
```

### 3. Supabase í…Œì´ë¸” ìƒì„±

```sql
-- university_notices í…Œì´ë¸” ìƒì„±
CREATE TABLE university_notices (
    id BIGSERIAL PRIMARY KEY,
    university_name VARCHAR(100) NOT NULL,
    notice_date DATE,
    notice_title TEXT NOT NULL,
    notice_link TEXT,
    crawled_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_university_date ON university_notices(university_name, notice_date);
CREATE INDEX idx_crawled_at ON university_notices(crawled_at);
```

### 4. n8n ì›¹í›… ì„¤ì •

n8nì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ GitHub Actionsë¥¼ íŠ¸ë¦¬ê±°í•˜ëŠ” ì›Œí¬í”Œë¡œìš°ë¥¼ ë§Œë“œì„¸ìš”:

```javascript
// n8n HTTP Request Node
{
  "method": "POST",
  "url": "https://api.github.com/repos/{owner}/{repo}/dispatches",
  "headers": {
    "Authorization": "token YOUR_GITHUB_TOKEN",
    "Accept": "application/vnd.github.everest-preview+json"
  },
  "body": {
    "event_type": "crawl-notices",
    "client_payload": {
      "batch_size": 50,
      "start_index": 0
    }
  }
}
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
university-notice-crawler/
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ crawl.yml                 # GitHub Actions ì›Œí¬í”Œë¡œìš°
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ crawler.py                # ë©”ì¸ í¬ë¡¤ëŸ¬ ë¡œì§
â”‚   â”œâ”€â”€ database.py               # Supabase ì—°ê²°
â”‚   â”œâ”€â”€ patterns.py               # íŒ¨í„´ ê°ì§€
â”‚   â”œâ”€â”€ templates.py              # í…œí”Œë¦¿ ê´€ë¦¬
â”‚   â””â”€â”€ utils.py                  # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ university_list.json      # ëŒ€í•™ ëª©ë¡
â”‚   â””â”€â”€ templates.json           # í…œí”Œë¦¿ ì •ì˜
â”œâ”€â”€ config.json                  # ì„¤ì • íŒŒì¼
â”œâ”€â”€ main.py                     # ë©”ì¸ ì‹¤í–‰ íŒŒì¼
â””â”€â”€ requirements.txt            # ì˜ì¡´ì„±
```

## âš™ï¸ ì„¤ì •

### config.json ì£¼ìš” ì„¤ì •

```json
{
  "crawler": {
    "timeout": 30,
    "retry_count": 3,
    "concurrent_limit": 5
  },
  "detection": {
    "min_confidence": 0.7,
    "min_notices": 3,
    "similarity_threshold": 0.8
  },
  "batch_size": 50
}
```

### í™˜ê²½ë³€ìˆ˜

- `BATCH_SIZE`: í•œ ë²ˆì— ì²˜ë¦¬í•  ëŒ€í•™ ìˆ˜ (ê¸°ë³¸ê°’: 50)
- `START_INDEX`: ì‹œì‘ ì¸ë±ìŠ¤ (ê¸°ë³¸ê°’: 0)
- `CRAWLER_TIMEOUT`: ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ê¸°ë³¸ê°’: 30ì´ˆ)
- `LOG_LEVEL`: ë¡œê·¸ ë ˆë²¨ (ê¸°ë³¸ê°’: INFO)

## ğŸ”„ ì‚¬ìš© ë°©ë²•

### ìë™ ì‹¤í–‰ (ê¶Œì¥)

1. **n8n íŠ¸ë¦¬ê±°**: ì„¤ì •ëœ ìŠ¤ì¼€ì¤„ì— ë”°ë¼ ìë™ ì‹¤í–‰
2. **ìˆ˜ë™ íŠ¸ë¦¬ê±°**: GitHub Actions íƒ­ì—ì„œ "Run workflow" í´ë¦­

### ë¡œì»¬ ì‹¤í–‰

```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export SUPABASE_URL="your-supabase-url"
export SUPABASE_KEY="your-supabase-key"

# ì‹¤í–‰
python main.py
```

### ë°°ì¹˜ ì‹¤í–‰

```bash
# íŠ¹ì • ë²”ìœ„ í¬ë¡¤ë§
BATCH_SIZE=20 START_INDEX=100 python main.py

# íŠ¹ì • ëŒ€í•™ë§Œ í¬ë¡¤ë§ (ì½”ë“œ ìˆ˜ì • í•„ìš”)
python main.py --universities="ì„œìš¸ëŒ€í•™êµ,ì—°ì„¸ëŒ€í•™êµ"
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë¡œê·¸

### GitHub Actions ë¡œê·¸

- **ì‹¤í–‰ ê²°ê³¼**: Actions íƒ­ì—ì„œ í™•ì¸
- **ì•„í‹°íŒ©íŠ¸**: ìƒì„¸ ë¡œê·¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥
- **ì‹¤í–‰ ì‹œê°„**: ë°°ì¹˜ë³„ ì²˜ë¦¬ ì‹œê°„ í™•ì¸

### ë¡œê·¸ íŒŒì¼

```
logs/
â”œâ”€â”€ crawler.log          # ì¼ë°˜ ì‹¤í–‰ ë¡œê·¸
â”œâ”€â”€ error.log           # ì—ëŸ¬ ë¡œê·¸
â””â”€â”€ crawl_report_*.json # ì‹¤í–‰ ê²°ê³¼ ë¦¬í¬íŠ¸
```

### ì„±ê³µë¥  ëª¨ë‹ˆí„°ë§

```json
{
  "statistics": {
    "ì „ì²´ ëŒ€í•™ ìˆ˜": 50,
    "ì„±ê³µ": 42,
    "ì‹¤íŒ¨": 8,
    "ì„±ê³µë¥ ": "84.0%",
    "ì´ ê³µì§€ì‚¬í•­ ìˆ˜": 1247
  },
  "methods": {
    "ìë™ ê°ì§€": 35,
    "í…œí”Œë¦¿ ì‚¬ìš©": 5,
    "ìˆ˜ë™ ì„¤ì •": 2
  }
}
```

## ğŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ìƒˆë¡œìš´ ëŒ€í•™ ì¶”ê°€

`data/university_list.json`ì— ëŒ€í•™ ì •ë³´ ì¶”ê°€:

```json
{
  "name": "ìƒˆë¡œìš´ëŒ€í•™êµ",
  "notice_url": "https://new-university.ac.kr/notice",
  "domain": "new-university.ac.kr",
  "region": "ì„œìš¸",
  "type": "ì‚¬ë¦½",
  "category": "ì¼ë°˜ëŒ€í•™"
}
```

### í…œí”Œë¦¿ ì¶”ê°€

`data/templates.json`ì— ìƒˆë¡œìš´ í…œí”Œë¦¿ ì‹œìŠ¤í…œ ì¶”ê°€:

```json
{
  "systems": {
    "new_system": {
      "name": "ìƒˆë¡œìš´ ì‹œìŠ¤í…œ",
      "indicators": ["new-system.com", "class=\"new-board\""],
      "selectors": {
        "list_selector": ".new-list tr",
        "title_selector": ".new-title a",
        "date_selector": ".new-date",
        "link_selector": "a"
      }
    }
  }
}
```

### íŒ¨í„´ ê°ì§€ íŠœë‹

`config.json`ì—ì„œ ê°ì§€ íŒŒë¼ë¯¸í„° ì¡°ì •:

```json
{
  "detection": {
    "min_confidence": 0.6,        # ì‹ ë¢°ë„ ì„ê³„ê°’ ë‚®ì¶¤
    "min_notices": 2,             # ìµœì†Œ ê³µì§€ì‚¬í•­ ìˆ˜ ë‚®ì¶¤
    "similarity_threshold": 0.7   # ìœ ì‚¬ë„ ì„ê³„ê°’ ë‚®ì¶¤
  }
}
```

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ

1. **Selenium ì—ëŸ¬**
   ```bash
   # Chrome ë“œë¼ì´ë²„ ì—…ë°ì´íŠ¸
   pip install --upgrade chromedriver-autoinstaller
   ```

2. **Supabase ì—°ê²° ì‹¤íŒ¨**
   ```bash
   # í™˜ê²½ë³€ìˆ˜ í™•ì¸
   echo $SUPABASE_URL
   echo $SUPABASE_KEY
   ```

3. **ë©”ëª¨ë¦¬ ë¶€ì¡±**
   ```json
   // config.jsonì—ì„œ ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
   {
     "batch_size": 20,
     "concurrent_limit": 3
   }
   ```

### ë””ë²„ê¹…

```bash
# ë””ë²„ê·¸ ëª¨ë“œ ì‹¤í–‰
LOG_LEVEL=DEBUG python main.py

# íŠ¹ì • ëŒ€í•™ë§Œ í…ŒìŠ¤íŠ¸
python -c "
from src.crawler import SmartCrawler
from src.utils import load_config
crawler = SmartCrawler(load_config())
result = crawler.crawl_university('https://test-university.ac.kr/notice', 'í…ŒìŠ¤íŠ¸ëŒ€í•™êµ')
print(result)
"
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### ê¶Œì¥ ì„¤ì •

- **ë°°ì¹˜ í¬ê¸°**: 50ê°œ (ë©”ëª¨ë¦¬ 8GB ê¸°ì¤€)
- **ë™ì‹œ ì‹¤í–‰**: 5ê°œ (ë„¤íŠ¸ì›Œí¬ ë¶€í•˜ ê³ ë ¤)
- **íƒ€ì„ì•„ì›ƒ**: 30ì´ˆ (ì•ˆì •ì„±ê³¼ ì†ë„ ê· í˜•)

### ìŠ¤ì¼€ì¼ë§

ëŒ€ê·œëª¨ ìš´ì˜ì‹œ ê³ ë ¤ì‚¬í•­:

1. **ë°°ì¹˜ ë¶„í• **: ì—¬ëŸ¬ ì›Œí¬í”Œë¡œìš°ë¡œ ë¶„ì‚°
2. **ìºì‹±**: Redis ìºì‹œ ì¶”ê°€
3. **ëª¨ë‹ˆí„°ë§**: Prometheus + Grafana
4. **ì•Œë¦¼**: Slack/Discord ì›¹í›… ì—°ë™

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ“ ì§€ì›

- **ì´ìŠˆ**: GitHub Issues
- **í† ë¡ **: GitHub Discussions
- **ì´ë©”ì¼**: support@crawler.com

---

**âš¡ ì„±ëŠ¥**: 200ê°œ ëŒ€í•™ ì•½ 15ë¶„ ë‚´ ì™„ë£Œ  
**ğŸ¯ ì •í™•ë„**: í‰ê·  85% ì´ìƒ ì„±ê³µë¥   
**ğŸ”„ ìë™í™”**: 24/7 ë¬´ì¸ ìš´ì˜ ê°€ëŠ¥
